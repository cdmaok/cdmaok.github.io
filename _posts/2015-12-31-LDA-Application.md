---
layout: post
title: LDA Application's Intro
category: Machine Learning
---
摘自[LDA漫游](http://yuedu.baidu.com/ebook/d0b441a8ccbff121dd36839a)

## LDA 主题模型
  LDA 模型的输入是语料集(M篇文章，V个单词)和一个预设主题数目K，产出是两个矩阵，一个是文章-主题矩阵(M*K),另外一个是主题-单词矩阵(K*V)。下面简单摘出一些简单的应用

### 文章的相似度
  根据文章-主题矩阵可以获得每篇文章的一个向量，可以计算两个向量的相似度。其中包括cos距离，KL距离，[Hellinger distance](https://en.wikipedia.org/wiki/Hellinger_distance)  

### TAG 生成程序
  获得文档的主题分布，从主题分布最高的某几个或者某个主题下面获取TopK的单词作为标签
   
### LDA + LR 个性化推荐
  1. 使用LDA生成文本的主题特征，然后加入到LR算法当中
  2. 根据用户点击数据生成user-topic矩阵，然后进行矩阵分解等。  

### Topic Rank
  1. 类似于停用词的概念，一些在所有词上分布均匀和在所有文章上分布均匀的主题没有意义，在排序中应该被排到后面去。
  2. 需要两个统计量，一个是主题-文章分布，一个是主题-单词分布，后者在原生的LDA输出中天然存在。另外一个要通过文章-主题分布转换得到。_公式待补_(将某一列累加然后归一化即可)，分别计算这两个距离跟[1/K,1/K,1/K,...1/K]和[1/v,1/v,...,1/V]的相似度(cos,KL,Pearson等)
  3. 然后这两个距离进行加权求和排序

### Word Rank
  1. 跟Topic Rank一样的道理，如果单词在所有topic中的概率相似，说明不是一个有较大意义的词汇。
  2. 对主题-单词概率矩阵进行 **转置归一化**，比较与[1/K,1/K,...,1/K]距离
